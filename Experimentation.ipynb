{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepar.dataset.time_series import TimeSeries\n",
    "from deepar.model.lstm import DeepARLearner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sunspots_df = pd.read_csv('../datasets/seed_datasets_current/56_sunspots/TRAIN/dataset_TRAIN/tables/learningData.csv')\n",
    "sunspots_df['year'] = pd.to_timedelta(pd.to_datetime(sunspots_df['year'], format='%Y')).dt.total_seconds()\n",
    "sunspots_ds_one = TimeSeries(sunspots_df, target_idx = 4, timestamp_idx = 1, index_col=0)"
   ]
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepar.dataset.time_series import TimeSeries, TimeSeriesTest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepar.model.learner import DeepARLearner\n",
    "\n",
    "sunspots_df = pd.read_csv('../datasets/seed_datasets_current/56_sunspots/TRAIN/dataset_TRAIN/tables/learningData.csv')\n",
    "# sunspots_df['sunspots'][5] = np.nan\n",
    "# sunspots_df['sunspots'][10] = np.nan\n",
    "# sunspots_df['sunspots'][15] = np.nan\n",
    "# sunspots_df['sunspots'][20] = np.nan\n",
    "# sunspots_df['sunspots'][25] = np.nan\n",
    "sunspots_df['year'] = pd.to_timedelta(pd.to_datetime(sunspots_df['year'], format='%Y')).dt.total_seconds()\n",
    "sunspots_ds_one = TimeSeries(sunspots_df, target_idx = 4, timestamp_idx = 1, index_col=0)\n",
    "\n",
    "learner = DeepARLearner(sunspots_ds_one, verbose=1)\n",
    "!rm -r ./tb_test\n",
    "learner.fit(epochs = 1, batches = 10, early_stopping = False, checkpoint_dir = \"./tb_test\")\n",
    "\n",
    "test_df = pd.read_csv('../datasets/seed_datasets_current/56_sunspots/TEST/dataset_TEST/tables/learningData.csv')\n",
    "test_df['year'] = pd.to_timedelta(pd.to_datetime(test_df['year'], format='%Y')).dt.total_seconds()\n",
    "test_ds = TimeSeriesTest(test_df, sunspots_ds_one, target_idx = 4, timestamp_idx = 1, index_col=0)\n",
    "\n",
    "preds = learner.predict(test_ds, horizon = None, samples = 1, include_all_training = True).reshape(-1)\n",
    "scores = pd.read_csv('../datasets/seed_datasets_current/56_sunspots/SCORE/dataset_SCORE/tables/learningData.csv')\n",
    "\n",
    "# evaluate compared to D3M test set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(scores['sunspots'], preds))\n",
    "print(f'rms: {rms}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepar.dataset.time_series import TimeSeries, TimeSeriesTest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepar.model.learner import DeepARLearner\n",
    "\n",
    "pop_df = pd.read_csv('../datasets/seed_datasets_current/LL1_736_population_spawn/TRAIN/dataset_TRAIN/tables/learningData.csv')\n",
    "pop_df = pop_df.set_index(['species', 'sector'])\n",
    "pop_df['group'] = pop_df.index\n",
    "pop_df['group'] = pop_df['group'].apply(lambda x: \" \".join(x))\n",
    "pop_df = pop_df.reset_index(drop=True)\n",
    "pop_df['day'] = pd.to_timedelta(pd.to_datetime(pop_df['day'], unit='D')).dt.total_seconds()\n",
    "pop_ds = TimeSeries(pop_df, target_idx = 2, timestamp_idx = 1, index_col=0, grouping_idx = 3, count_data = True)\n",
    "\n",
    "learner = DeepARLearner(pop_ds, verbose = 1)\n",
    "learner.fit(epochs = 1, batches = 10, early_stopping = False)\n",
    "\n",
    "test_df = pd.read_csv('../datasets/seed_datasets_current/LL1_736_population_spawn/TEST/dataset_TEST/tables/learningData.csv')\n",
    "test_df = test_df.set_index(['species', 'sector'])\n",
    "test_df['group'] = test_df.index\n",
    "test_df['group'] = test_df['group'].apply(lambda x: \" \".join(x))\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_df['day'] = pd.to_timedelta(pd.to_datetime(test_df['day'], unit='D')).dt.total_seconds()\n",
    "test_ds = TimeSeriesTest(test_df, pop_ds, target_idx = 2, timestamp_idx = 1, index_col=0, grouping_idx = 3)\n",
    "\n",
    "preds = learner.predict(test_ds, horizon = None, samples = 1, include_all_training = True)\n",
    "\n",
    "# evaluate compared to D3M test set\n",
    "scores = pd.read_csv('../datasets/seed_datasets_current/LL1_736_population_spawn/SCORE/dataset_SCORE/tables/learningData.csv')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "print(scores['count'].shape)\n",
    "# rms = sqrt(mean_squared_error(scores['count'], preds))\n",
    "# print(f'rms: {rms}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy.random import normal\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "window = 20\n",
    "features = 9\n",
    "def get_sample_prediction(sample, fn):\n",
    "    sample = np.array(sample).reshape(1, window, features)\n",
    "    output = fn([sample])\n",
    "    samples = []\n",
    "    for mu,sigma in zip(output[0].reshape(window), output[1].reshape(window)):\n",
    "        samples.append(normal(loc=mu, scale=np.sqrt(sigma), size=1)[0])\n",
    "    return np.array(samples)\n",
    "\n",
    "batch = sunspots_ds_one.next_batch(1, window)\n",
    "ress = []\n",
    "for i in range(300):\n",
    "    ress.append(get_sample_prediction(batch[0], dp_model.predict_theta_from_input))\n",
    "\n",
    "res_df = pd.DataFrame(ress).T\n",
    "tot_res = res_df\n",
    "\n",
    "\n",
    "plt.plot(batch[1].reshape(window), linewidth=6)\n",
    "tot_res['mu'] = tot_res.apply(lambda x: np.mean(x), axis=1)\n",
    "tot_res['upper'] = tot_res.apply(lambda x: np.mean(x) + np.std(x), axis=1)\n",
    "tot_res['lower'] = tot_res.apply(lambda x: np.mean(x) - np.std(x), axis=1)\n",
    "tot_res['two_upper'] = tot_res.apply(lambda x: np.mean(x) + 2*np.std(x), axis=1)\n",
    "tot_res['two_lower'] = tot_res.apply(lambda x: np.mean(x) - 2*np.std(x), axis=1)\n",
    "\n",
    "\n",
    "plt.plot(tot_res.mu, 'bo')\n",
    "plt.plot(tot_res.mu, linewidth=2)\n",
    "plt.fill_between(x = tot_res.index, y1=tot_res.lower, y2=tot_res.upper, alpha=0.5)\n",
    "plt.fill_between(x = tot_res.index, y1=tot_res.two_lower, y2=tot_res.two_upper, alpha=0.5)\n",
    "plt.title('Prediction uncertainty')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepar.model.loss import negative_binomial_likelihood\n",
    "from deepar.model.loss import gaussian_likelihood\n",
    "import tensorflow as tf\n",
    "\n",
    "sigma = 1.0\n",
    "sigma1 = 2.0\n",
    "sigma2 = 4.0\n",
    "g = gaussian_likelihood([sigma] * 3)\n",
    "b = negative_binomial_likelihood([sigma] * 3)\n",
    "b1 = negative_binomial_likelihood([sigma1] * 3)\n",
    "b2 = negative_binomial_likelihood([sigma2] * 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y_true = tf.convert_to_tensor([1,1,1], dtype=tf.float32)\n",
    "    y_pred0 = tf.convert_to_tensor([1,1,1], dtype=tf.float32)\n",
    "    y_pred1 = tf.convert_to_tensor([2,2,2], dtype=tf.float32)\n",
    "    y_pred2 = tf.convert_to_tensor([4,4,4], dtype=tf.float32)\n",
    "    y_pred3 = tf.convert_to_tensor([8,8,8], dtype=tf.float32)\n",
    "    print(b(y_true, y_pred0).eval())\n",
    "    print(b(y_true, y_pred1).eval())\n",
    "    print(b(y_true, y_pred2).eval())\n",
    "    print(b(y_true, y_pred3).eval())\n",
    "    print(b1(y_true, y_pred0).eval())\n",
    "    print(b2(y_true, y_pred0).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.to_datetime(\"21/11/06 16:30\", format=\"%d/%m/%y %H:%M\")\n",
    "x.timetuple().tm_yday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('cat').apply(lambda x: x.count())['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('cat').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, c_d in df.groupby('cat'):\n",
    "    c_d['age'] = c_d.index\n",
    "    print(c_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('age', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = df.groupby('cat').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age1'] = range(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df[[0,1]] = StandardScaler().fit_transform(df[[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + df.groupby('cat')[0].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}