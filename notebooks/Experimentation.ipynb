{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "logger.setLevel(logging.INFO)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from deepar import TimeSeriesTrain, TimeSeriesTest\n",
    "\n",
    "# sunspots_df = pd.read_csv('test_data/56_sunspots_MIN_METADATA/TRAIN/dataset_TRAIN/tables/learningData.csv')\n",
    "# sunspots_df['year'] = pd.to_datetime(sunspots_df['year'], format='%Y')\n",
    "# sunspots_ds_one = TimeSeriesTrain(\n",
    "#     sunspots_df, \n",
    "#     target_idx = 4, \n",
    "#     timestamp_idx = 1, \n",
    "#     index_col=0, \n",
    "#     freq = 'YS'\n",
    "# )\n",
    "# test_df = pd.read_csv('test_data/56_sunspots_MIN_METADATA/TEST/dataset_TEST/tables/learningData.csv')\n",
    "# test_df['year'] = pd.to_datetime(test_df['year'], format='%Y')\n",
    "# test_ds = TimeSeriesTest(sunspots_ds_one, test_df, target_idx = 4)\n",
    "\n",
    "pop_df = pd.read_csv('test_data/LL1_736_population_spawn_MIN_METADATA/TRAIN/dataset_TRAIN/tables/learningData.csv')\n",
    "pop_df['day'] = pd.to_datetime(pop_df['day'], unit='D')\n",
    "pop_ds = TimeSeriesTrain(\n",
    "    pop_df, \n",
    "    target_idx = 4, \n",
    "    timestamp_idx = 3, \n",
    "    index_col=0, \n",
    "    freq = 'D', \n",
    "    cat_indices = [1,2], \n",
    "    count_data = True\n",
    ")\n",
    "\n",
    "pop_test_df = pd.read_csv('test_data/LL1_736_population_spawn_MIN_METADATA/TEST/dataset_TEST/tables/learningData.csv')\n",
    "pop_test_df['day'] = pd.to_datetime(pop_test_df['day'], unit = 'D')\n",
    "pop_test_ds = TimeSeriesTest(pop_ds, pop_test_df, target_idx = 4)\n",
    "\n",
    "# stock_df = pd.read_csv('test_data/LL1_736_stock_market_MIN_METADATA/TRAIN/dataset_TRAIN/tables/learningData.csv')\n",
    "# stock_df['Date'] = pd.to_datetime(stock_df['Date'], format='%m/%d/%Y')\n",
    "# stock_ds = TimeSeriesTrain(\n",
    "#     stock_df, \n",
    "#     target_idx = 3, \n",
    "#     timestamp_idx = 2, \n",
    "#     index_col=0, \n",
    "#     freq = 'D', \n",
    "#     cat_indices = [1], \n",
    "# )\n",
    "\n",
    "# stock_test_df = pd.read_csv('test_data/LL1_736_stock_market_MIN_METADATA/TEST/dataset_TEST/tables/learningData.csv')\n",
    "# stock_test_df['Date'] = pd.to_datetime(stock_test_df['Date'], format='%m/%d/%Y')\n",
    "# stock_test_ds = TimeSeriesTest(stock_ds, stock_test_df, target_idx = 3)\n",
    "\n",
    "from deepar import DeepARLearner\n",
    "\n",
    "# learner = DeepARLearner(sunspots_ds_one)\n",
    "# learner.fit(epochs = 1, steps_per_epoch = 5, tensorboard = False)\n",
    "# preds = learner.predict(test_ds, \n",
    "#                         point_estimate = True, \n",
    "#                         include_all_training = False, \n",
    "#                         return_in_sample_predictions = True)\n",
    "\n",
    "learner = DeepARLearner(pop_ds)\n",
    "learner.fit(epochs = 1, steps_per_epoch = 5, tensorboard = False)\n",
    "preds = learner.predict(pop_test_ds, \n",
    "                        point_estimate = True, \n",
    "                        include_all_training = False, \n",
    "                        return_in_sample_predictions = True)\n",
    "\n",
    "# learner = DeepARLearner(stock_ds)\n",
    "# learner.fit(epochs = 1, steps_per_epoch = 5, tensorboard = False)\n",
    "# preds = learner.predict(stock_test_ds, \n",
    "#                         point_estimate = True, \n",
    "#                         include_all_training = False, \n",
    "#                         return_in_sample_predictions = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepar.model.loss import negative_binomial_likelihood\n",
    "from deepar.model.loss import gaussian_likelihood\n",
    "import tensorflow as tf\n",
    "\n",
    "sigma = 1.0\n",
    "sigma1 = 2.0\n",
    "sigma2 = 4.0\n",
    "g = gaussian_likelihood([sigma] * 3)\n",
    "b = negative_binomial_likelihood([sigma] * 3)\n",
    "b1 = negative_binomial_likelihood([sigma1] * 3)\n",
    "b2 = negative_binomial_likelihood([sigma2] * 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y_true = tf.convert_to_tensor([1,1,1], dtype=tf.float32)\n",
    "    y_pred0 = tf.convert_to_tensor([1,1,1], dtype=tf.float32)\n",
    "    y_pred1 = tf.convert_to_tensor([2,2,2], dtype=tf.float32)\n",
    "    y_pred2 = tf.convert_to_tensor([4,4,4], dtype=tf.float32)\n",
    "    y_pred3 = tf.convert_to_tensor([8,8,8], dtype=tf.float32)\n",
    "    print(b(y_true, y_pred0).eval())\n",
    "    print(b(y_true, y_pred1).eval())\n",
    "    print(b(y_true, y_pred2).eval())\n",
    "    print(b(y_true, y_pred3).eval())\n",
    "    print(b1(y_true, y_pred0).eval())\n",
    "    print(b2(y_true, y_pred0).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}